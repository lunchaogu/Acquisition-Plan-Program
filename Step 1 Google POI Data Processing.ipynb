{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "import project_fuctions as pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key and url for Google map POI scraping\n",
    "API_KEY = Google_place_key\n",
    "url = 'https://maps.googleapis.com/maps/api/place/textsearch/json'\n",
    "\n",
    "# The country to process and file directions\n",
    "country = 'Korea' # If Abbre. of country is commonly used, joined names with '|'. For exampe: United Kingdom|UK\n",
    "route_input = route_input # The attraction list for POI retrieving\n",
    "route_export = route_output\n",
    "route_POI_raw_data = route_raw_data\n",
    "\n",
    "# Threshold to filter POIs\n",
    "review_threshold = 0\n",
    "\n",
    "OpenAI_key = OpenAI_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get POI list througn Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POI_to_get = pd.read_csv(route_input)\n",
    "POI_places = POI_to_get.values.tolist()\n",
    "POI_result = pd.DataFrame()\n",
    "failed = []\n",
    "n = 0\n",
    "page_token = None\n",
    "for place in POI_places:\n",
    "    print(f'request No.{n} {place[0]}, {place[1]}')\n",
    "    params = {\n",
    "    'query': f'{place[0]}, {place[1]}',\n",
    "    'key': API_KEY,\n",
    "        #'pagetoken' : page_token,\n",
    "        #'type' : \"amusement_park\",\n",
    "        }\n",
    "    result = requests.get(url, params=params)\n",
    "    #Convert data into json type first and dataframe then\n",
    "    result_js = result.json()\n",
    "    result_df = pd.json_normalize(result_js['results'])\n",
    "    if len(result_df) > 0: \n",
    "        print(f'{result_df.loc[0][\"name\"]}')\n",
    "        result_df['Origin'] = pd.Series([place for x in range(len(result_df.index))])\n",
    "    #if len(result_df) == 0\n",
    "    #Check if there is next page and send the token to params\n",
    "    #if 'next_page_token' in result_js:\n",
    "    #   page_token = result_js['next_page_token']\n",
    "    #else:\n",
    "    #    page_token = None\n",
    "        POI_result = pd.concat([POI_result,result_df])\n",
    "        print(f'No.{n} successed')\n",
    "    else: \n",
    "        failed.append(n)\n",
    "        print(f'No.{n} failed')\n",
    "    n = n+1\n",
    "    time.sleep(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Update the admission and category by dynamically scraping Google Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POI_list = pf.cleanup(POI_result,review_threshold,country)\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "url_part = 'https://www.google.com/maps/place/?q=place_id:'\n",
    "driver.execute_script(\"document.body.style.zoom='50%'\")\n",
    "\n",
    "hotel_path = '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/div[1]/div[2]/div/div/span/span/span/span[2]/span/span'\n",
    "\n",
    "for index, item in POI_list.iterrows():\n",
    "    url = url_part + item['place_id']\n",
    "    driver.get(url)\n",
    " \n",
    "    try:\n",
    "        WebDriverWait(driver, 2, 0.2).until(EC.visibility_of_element_located((By.CLASS_NAME,\"drwWxc\")),\"No value\")       \n",
    "        admission = driver.find_element(By.CLASS_NAME,\"drwWxc\").text\n",
    "    except:\n",
    "        admission = \"Unknown\"\n",
    "    \n",
    "    try:\n",
    "        place_type = driver.find_element(By.CLASS_NAME,'DkEaL').text\n",
    "    except:\n",
    "        try:\n",
    "            WebDriverWait(driver, 1, 0.2).until(EC.visibility_of_element_located((By.XPATH,hotel_path)),\"No value\")       \n",
    "            place_type = driver.find_element(By.XPATH,hotel_path).text\n",
    "        except:\n",
    "            place_type = \"Unknown\"\n",
    "\n",
    "    try:\n",
    "        description = driver.find_element(By.CLASS_NAME,'PYvSYb').text\n",
    "    except:\n",
    "        description = \"Unknown\"\n",
    "    \n",
    "    POI_list.loc[index, 'Place Type'] = place_type\n",
    "    POI_list.loc[index, 'Free or Paid'] = admission\n",
    "    POI_list.loc[index, 'Description'] = description\n",
    "    print(f\"{index} - {item['name']} is {place_type}, its admission is {admission}\")\n",
    "    if (index+1)%100 == 0: POI_list.to_csv(route_export, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Categorize BU Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = '[\"Ancient Ruins\",\"Aquariums\",\"Cable Car & Gondola & Skywheels\", \"Castles & Palaces\", \"Cathedral & Churches\", \"Farms\", \"Gardens & Parks\", \"Museums & Galleries\", \"Natural Landscape\", \"Observation Decks & Towers\", \"Playgrounds\", \"Temples & Shrines\", \"Theme Park\", \"Villages\", \"Shows & Musicals\", \"Water Parks\", \"Zoos & Animal Parks\", \"Sports\", \"Not Attraction - Lodging\", \"Not Attraction - F&B\", \"Not Attraction - Shopping\", \"Not Attraction - Transportation\",\"not sure\"]'\n",
    "for index, row in POI_list.iterrows():\n",
    "    attraction = row.loc['name']\n",
    "    google_tag = row.loc['Place Type']\n",
    "    description = row.loc['Description']\n",
    "    prompt = f\"\"\"\n",
    "    Your task is to categorize the attaction delimited by <> with only one label from the label list delimited by <tag></tag>.\n",
    "    \n",
    "    Followings are instructions:\n",
    "    1. The description of the attraction is delimited by %%, which you can take for reference, but do not return content in it!\n",
    "    2. You can refer to the tags given by google map delimited by ```, but do not use any of those tags!\n",
    "    3. The response should be exactly from label list delimited by <tag></tag>, no punctuation included.\n",
    "\n",
    "    attraction: <{attraction}>\n",
    "    label_list: <tag>{label_list}</tag>\n",
    "    attraction description: %%{description}%%\n",
    "    Tag List: ```{google_tag}```\n",
    "    \"\"\"\n",
    "    response = pf.get_completion(prompt)\n",
    "    POI_list.loc[index, 'BU Level 3'] = response\n",
    "    print(f'{index}: {attraction} labeled: {response}')\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POI_list['Gmap URL'] = url_part + POI_list['place_id']\n",
    "column_order = ['state','city','name','rating','user_ratings_total','Free or Paid','Place Type','Gmap URL','BU Level 3','formatted_address','place_id','types','Description']\n",
    "POI_list = POI_list[column_order]\n",
    "POI_list.to_csv(route_export, index=False)\n",
    "POI_list['Gmap URL'].to_csv('/Users/glen.gu/Documents/Python Project/Acquisition Plan/Frence/Lang/URL_FR_to_apify_missing_1206.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
