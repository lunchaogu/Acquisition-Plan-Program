{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import chromadb\n",
    "import project_function as pf\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_head = 'https://www.traveloka.com/en-id/activities/vietnam/product/'\n",
    "AID_column_name = 'Activity' #AID column name\n",
    "AID_code_column_name = 'comp.aid' #AID code column name\n",
    "location_column_name = 'City'\n",
    "AID_to_identify = pd.read_csv('/content/Traveloka_AID_Raw_Vietnam.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Traveloca POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AID_to_identify['url'] = url_head + AID_to_identify[AID_code_column_name].astype(str) + '/'\n",
    "for index, item in AID_to_identify.iterrows():\n",
    "    url = item['url']\n",
    "    title = item[AID_column_name]\n",
    "    response = requests.get(url, headers=pf.headers_traveloca)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    #Retrive the location of the activity\n",
    "    location = soup.select('#__next > div.css-1dbjc4n.r-391gc0.r-bnwqim.r-13qz1uu.r-1e2svnr > div.css-1dbjc4n.r-6koalj.r-18u37iz.r-1777fci.r-13qz1uu.r-184en5c > div > div.css-1dbjc4n.r-eqz5dr.r-dj2ral > div.css-1dbjc4n.r-14lw9ot.r-kdyh1x.r-da5iq2.r-1udh08x.r-nsbfu8 > div.css-1dbjc4n.r-6gpygo.r-kzbkwu.r-1pn2ns4.r-tskmnb > div > div > div:nth-child(2) > div')\n",
    "    if len(location)==0:\n",
    "      AID_to_identify.loc[index,'location']=\"none\"\n",
    "      AID_to_identify.loc[index,'response']=\"none\"\n",
    "      continue\n",
    "    else:\n",
    "      AID_to_identify.loc[index,'location'] = location[0].text\n",
    "\n",
    "    #Retrive the content of the activity\n",
    "    p_position = soup.select('p')\n",
    "    summary = str()\n",
    "    for item in p_position:\n",
    "        summary = summary + '\\n' + item.text\n",
    "\n",
    "    #Identify the attraction mentioned\n",
    "    prompt = f\"\"\"\n",
    "    Your task is to identify all the attractions I will visit if I take the travelling product according to both tiltle and summary provided, delimited with <>.\n",
    "    Exclude the pick-up point, drop-off point, and any information about transfer, activity, experience, shopping, restaurant and cruise.\n",
    "    If it is a theme park, just give me the name of the park, no need to provide subattractions under the park.\n",
    "    Please return the specific names of the attractions, joined by commas.\n",
    "    If no attractions is mentioned, return none.\n",
    "    Product: <{title}: {summary}>\n",
    "    \"\"\"\n",
    "    response = pf.get_completion(prompt)\n",
    "    AID_to_identify.loc[index, 'response'] = response\n",
    "    print(f'{index+1} out of {len(AID_to_identify)}:Activity-{title} taken place in {location[0].text} - attractions: {response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify GYG POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in AID_to_identify.iterrows():\n",
    "    url = row['AID Link']\n",
    "    driver.get(url)\n",
    "    \n",
    "    try:\n",
    "        WebDriverWait(driver, 5, 0.5).until(EC.visibility_of_element_located((By.CSS_SELECTOR,\"#activity-experience > section.full-description.activity-experience__item\")))\n",
    "        element = driver.find_element(By.CSS_SELECTOR, \"#activity-experience > section.full-description.activity-experience__item > div > div.activity-accordion-item__content--hidden.activity-accordion-item__content > section > div.toggle-content__label-placeholder > button\")\n",
    "        # Scroll to the buttun and click\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "        summary = driver.find_element(By.CSS_SELECTOR,\"#activity-experience > section.full-description.activity-experience__item > div > div.activity-accordion-item__content--hidden.activity-accordion-item__content > section > div.toggle-content__content.toggle-content__content--packable > div\").text\n",
    "    except NoSuchElementException:\n",
    "        summary = driver.find_element(By.CSS_SELECTOR,\"#activity-experience > section.full-description.activity-experience__item > div > div.activity-accordion-item__content--hidden.activity-accordion-item__content > section > div.toggle-content__content > div\").text\n",
    "    except TimeoutException:\n",
    "        summary = ''\n",
    "\n",
    "    title = row['AID Title']\n",
    "    prompt = f\"\"\"\n",
    "    Your task is to identify all the attractions I will visit if I take the travelling product with the tiltle and summary provided, delimited with <>.\n",
    "    Exclude the pick-up point, drop-off point, and any information about transfer, activity, experience, shopping, restaurant and cruise.\n",
    "    The attraction should be a proper noun for a speicific attraction, if the word is a generic noun, or if the word is the name of a city or area, do not return.\n",
    "    Please return the specific names of the attractions, joined by a comma.\n",
    "    If no attractions is mentioned, return none.\n",
    "    Product: <{title}: {summary}>\n",
    "    \"\"\"\n",
    "    response = pf.get_completion(prompt)\n",
    "    AID_to_identify.loc[index, 'response'] = response\n",
    "    print(f'{index+1} of {len(AID_to_identify)}. Activity :{title} - {response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Klook POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AID_to_identify['id'] = AID_to_identify[AID_column_name].str.extract(r'(\\d+)\\s*-\\s*')\n",
    "AID_to_identify['url'] = url_head + AID_to_identify['id'] + '/'\n",
    "\n",
    "for index, item in AID_to_identify.iterrows():\n",
    "    time.sleep(random.uniform(2, 5))\n",
    "    url = item['url']\n",
    "    title = item['Activity']\n",
    "    response = requests.get(url, headers=pf.headers_klook)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    li_position = soup.select('.exp-highlights-content-wrap > div > div > div > ul > li')\n",
    "    \n",
    "    summary = str()\n",
    "    for item in li_position:\n",
    "        summary = summary + '\\n' + item.text\n",
    "        \n",
    "    prompt = f\"\"\"\n",
    "    Your task is to identify all the attractions I will visit if I take the travelling product with the tiltle and summary provided, delimited with <>. \n",
    "    Exclude the pick-up point, drop-off point, and any information about transfer, activity, experience, shopping, restaurant and cruise.\n",
    "    The attraction should be a proper noun for a specific attracion, if the word is a generic noun describing a set of places, such as temples, do not return.\n",
    "    Please return the specific names of the attractions, joined by a comma.\n",
    "    If no attractions is mentioned, return none.\n",
    "    Product: <{title}: {summary}>\n",
    "    \"\"\"\n",
    "    response = pf.get_completion(prompt)\n",
    "    AID_to_identify.loc[index, 'response'] = response\n",
    "    print(f'{index+1} of {len(AID_to_identify)}. Activity :{title} - {response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AID_identified = pf.explode_AID(AID_to_identify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping AID & POI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a CSV file\n",
    "poi_df = pd.read_csv('/content/POI_Korea_cleanup_labelled.csv')\n",
    "to_match_df = pd.read_csv('/content/Klook_AID_identified_Korea.csv')\n",
    "poi_df['id'] = poi_df.index\n",
    "\n",
    "openai_api_key = \"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\"\n",
    "query_relevant_columns = [\"Activity_seperated\", \"Dimension level 2\"]\n",
    "categories_relevant_columns = [\"name\",\"city\"]\n",
    "category_id_column_name = \"id\"\n",
    "query_column_name = \"Activity\"\n",
    "\n",
    "def form_detail_text(row, columns):\n",
    "    to_return = \"\"\n",
    "    for ind, prop in enumerate(columns):\n",
    "        if (ind > 0):\n",
    "            to_return += \" in \"\n",
    "        to_return += str(row[prop])\n",
    "    return to_return\n",
    "\n",
    "def combine_query_body(row):\n",
    "    return form_detail_text(row, query_relevant_columns)\n",
    "\n",
    "def combine_body(row):\n",
    "    return form_detail_text(row, categories_relevant_columns)\n",
    "\n",
    "to_match_df[\"detail_info\"] = to_match_df.apply(combine_query_body, axis=1)\n",
    "poi_df[\"body_text\"] = poi_df.apply(combine_body, axis=1)\n",
    "poi_df[category_id_column_name] = poi_df[category_id_column_name].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create Embeddings (run 一次就好，不要不断建立 embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Use Open AI embeddings\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=openai_api_key,\n",
    "                model_name=\"text-embedding-ada-002\"\n",
    "            )\n",
    "\n",
    "# setup Chroma in-memory, for easy prototyping. Can add persistence easily!\n",
    "client = chromadb.Client()\n",
    "collection = client.get_or_create_collection(\"compare_table\", embedding_function = openai_ef)\n",
    "# remove old data\n",
    "#client.delete_collection(name=\"compare_table\")\n",
    "#collection = client.create_collection(\"compare_table\", embedding_function = openai_ef)\n",
    "\n",
    "# Add docs to the collection. Can also update and delete. Row-based API coming soon!\n",
    "collection.add(\n",
    "    documents=list(poi_df.loc[2000:, \"body_text\"]), # You can skip that and add your own embeddings as well\n",
    "    metadatas=poi_df.loc[2000:].to_dict('records'), # filter on these!\n",
    "    ids=list(poi_df.loc[2000:][category_id_column_name]), # unique for each doc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Qurey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_match_df = to_match_df\n",
    "\n",
    "def check_if_valid_match(x):\n",
    "    option_list = \"\"\n",
    "    options = json.loads(x[\"support_reason\"])[0]\n",
    "\n",
    "    for ind, opt in enumerate(options):\n",
    "        option_list += f'\\n- {opt[\"name\"]} [ID: {opt[\"id\"]}]'\n",
    "\n",
    "\n",
    "    prompt_template = \"\"\"You are an experienced travel industry expert, knowing many travel spots and attractions around the world. Below is a list of attractions:\n",
    "\n",
    "\n",
    "        ---------------\n",
    "\n",
    "        {option_list}\n",
    "\n",
    "        ---------------\n",
    "\n",
    "        Please Identify if the travel spot \"{query}\" is possibly mentioned in the list above in any language.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    prompt = prompt_template.replace(\"{option_list}\", option_list).replace(\"{query}\", x[query_column_name])\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    convo = [{\"role\":\"system\",\"content\": prompt}]\n",
    "\n",
    "    answer_1 = pf.completion(convo, \"gpt-3.5-turbo\")\n",
    "\n",
    "    convo.append({\n",
    "        \"role\":\"assistant\",\n",
    "        \"content\": answer_1[\"content\"]\n",
    "    })\n",
    "    convo.append({\n",
    "        \"role\":\"system\",\n",
    "        \"content\": \"\"\"\n",
    "        You should return the answer in this format:\n",
    "\n",
    "        {\n",
    "            \"attraction_name\": String // name of the matching travel spot or attraction, leave it empty if no match\n",
    "            \"has_a_match\": Boolean // true or false, whether there there is a match\n",
    "            \"id\": String // The ID of the matched travel spot, leave it empty if no match\n",
    "\n",
    "        }\n",
    "        \"\"\"\n",
    "    })\n",
    "\n",
    "    answer_2 = pf.completion(convo, \"gpt-3.5-turbo\")\n",
    "\n",
    "    # answer_2 = completion(convo, \"gpt-3.5-turbo\", {\n",
    "    #     \"function_call_component\": [\n",
    "    #       {\n",
    "    #         \"name\": \"find_if_has_a_match\",\n",
    "    #         \"description\": \"Generate FAQ and body content for SEO of a page\",\n",
    "    #         \"parameters\": {\n",
    "    #             \"type\": \"object\",\n",
    "    #             \"properties\": {\n",
    "    #                 \"has_a_match\": {\n",
    "    #                     \"type\": \"boolean\",\n",
    "    #                     \"description\": \"whether there there is a match\"\n",
    "    #                 },\n",
    "    #                 \"id\": {\n",
    "    #                     \"type\": \"string\",\n",
    "    #                     \"description\": \"The ID of the matched travel spot, leave it empty if no match\"\n",
    "    #                 }\n",
    "    #             },\n",
    "    #             \"required\": [\"has_a_match\",\"id\"]\n",
    "    #         }\n",
    "    #       }\n",
    "    #     ]\n",
    "    # })\n",
    "\n",
    "    convo.append({\n",
    "        \"role\":\"assistant\",\n",
    "        \"content\": answer_2[\"content\"]\n",
    "    })\n",
    "\n",
    "    print(convo)\n",
    "\n",
    "    return pd.Series([answer_2[\"content\"], answer_2[\"cost\"]])\n",
    "\n",
    "def map_function(x):\n",
    "    # Query/search 2 most similar results. You can also .get by id\n",
    "    results = collection.query(\n",
    "        query_texts=[x[\"detail_info\"]],\n",
    "        n_results=5,\n",
    "        # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "        # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
    "    )\n",
    "    main_id = results[\"metadatas\"][0][0][category_id_column_name]\n",
    "    similar_result_list = json.dumps(results[\"metadatas\"], ensure_ascii=False)\n",
    "    return pd.Series([similar_result_list])\n",
    "\n",
    "to_match_df[[\"support_reason\"]] = to_match_df.apply(map_function, axis=1)\n",
    "\n",
    "to_match_df[[\"has_match\",\"gpt_cost\"]] = to_match_df.apply(check_if_valid_match, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Eliminate NA value and duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AID_to_match = AID_identified[~AID_identified['Activity_seperated'].isna()]\n",
    "AID_to_match = AID_to_match[AID_identified['Activity_seperated']!='none']\n",
    "AID_to_match['Activity_seperated'] = AID_to_match['Activity_seperated'].apply(lambda x: x.lower())\n",
    "AID_to_match = AID_to_match.drop_duplicates(subset=['Activity_seperated']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Initiate Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('D:/Glen/LearningPython/Web Crawler/chromedriver.exe')\n",
    "url = 'https://map.google.com/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in AID_to_match.iterrows():\n",
    "    attraction = row['Activity_seperated']\n",
    "    location = row[location_column_name]\n",
    "    query = attraction + ', ' + location \n",
    "    try:    \n",
    "        mapping_result = pf.gmap_mapping(query, url)\n",
    "    except:\n",
    "        driver.get(url)\n",
    "        mapping_result = pf.gmap_mapping(query, url)\n",
    "    max_review = max(mapping_result, key=lambda x: x['review'] if x['review'] is not None else float('-inf'))['POI_name']\n",
    "    AID_to_match.loc[index, 'POI_Max_review'] = max_review\n",
    "    AID_to_match.loc[index, 'gmap_mapping']=str(mapping_result)\n",
    "    AID_to_match.loc[index, 'probability']=1/len(mapping_result)\n",
    "    print(f'{index+1} of {len(AID_to_match)}. result of {query} is {max_review}: \"{round(1/len(mapping_result) * 100)}%\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge mapping results and AID data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AID_identified['Activity_seperated_lower'] = AID_identified['Activity_seperated'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "AID_matched = pd.merge(AID_identified,AID_to_match[['Activity_seperated','POI_Max_review','gmap_mapping','probability']],\n",
    "                       how=\"left\",\n",
    "                       left_on='Activity_seperated_lower',\n",
    "                       right_on='Activity_seperated')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
